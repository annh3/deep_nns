{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98834f71-d037-434f-9f33-3c1ecc89b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq import train_epoch, get_dataloader, EncoderRNN, AttnDecoderRNN, prepareData\n",
    "import time\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06295204-519f-4fac-b66f-f9b0afd43046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffdaf278-91e9-412a-bd41-6b022d730dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9def668-fe61-4f4d-bf21-99f9a314bd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 135842 sentence pairs\n",
      "Trimmed to 11362 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4596\n",
      "eng 2989\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe341320-3c3a-4230-88e4-0332beb3e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11da24db-31a7-4cd9-ae36-f80a5a85394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=1, plot_every=5):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d1366f0-662e-432f-ae7d-99d933bb1940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 16s (- 55m 24s) (1 0%) 2.5192\n",
      "0m 33s (- 55m 8s) (2 1%) 1.6800\n",
      "0m 48s (- 53m 37s) (3 1%) 1.4019\n",
      "1m 4s (- 52m 38s) (4 2%) 1.2008\n",
      "1m 19s (- 51m 39s) (5 2%) 1.0373\n",
      "1m 35s (- 51m 14s) (6 3%) 0.8991\n",
      "1m 51s (- 51m 24s) (7 3%) 0.7845\n",
      "2m 8s (- 51m 29s) (8 4%) 0.6863\n",
      "2m 23s (- 50m 42s) (9 4%) 0.6013\n",
      "2m 38s (- 50m 4s) (10 5%) 0.5257\n",
      "2m 52s (- 49m 32s) (11 5%) 0.4607\n",
      "3m 7s (- 49m 3s) (12 6%) 0.4064\n",
      "3m 22s (- 48m 35s) (13 6%) 0.3582\n",
      "3m 37s (- 48m 13s) (14 7%) 0.3170\n",
      "3m 52s (- 47m 48s) (15 7%) 0.2822\n",
      "4m 7s (- 47m 25s) (16 8%) 0.2525\n",
      "4m 22s (- 47m 1s) (17 8%) 0.2220\n",
      "4m 37s (- 46m 40s) (18 9%) 0.1990\n",
      "4m 51s (- 46m 18s) (19 9%) 0.1786\n",
      "5m 6s (- 45m 59s) (20 10%) 0.1616\n",
      "5m 21s (- 45m 39s) (21 10%) 0.1458\n",
      "5m 36s (- 45m 20s) (22 11%) 0.1337\n",
      "5m 50s (- 45m 0s) (23 11%) 0.1204\n",
      "6m 5s (- 44m 41s) (24 12%) 0.1134\n",
      "6m 20s (- 44m 23s) (25 12%) 0.1060\n",
      "6m 34s (- 44m 3s) (26 13%) 0.0993\n",
      "6m 49s (- 43m 45s) (27 13%) 0.0957\n",
      "7m 4s (- 43m 28s) (28 14%) 0.0845\n",
      "7m 19s (- 43m 11s) (29 14%) 0.0826\n",
      "7m 34s (- 42m 54s) (30 15%) 0.0776\n",
      "7m 49s (- 42m 37s) (31 15%) 0.0702\n",
      "8m 3s (- 42m 19s) (32 16%) 0.0669\n",
      "8m 18s (- 42m 2s) (33 16%) 0.0647\n",
      "8m 33s (- 41m 46s) (34 17%) 0.0620\n",
      "8m 48s (- 41m 29s) (35 17%) 0.0592\n",
      "9m 2s (- 41m 12s) (36 18%) 0.0557\n",
      "9m 17s (- 40m 57s) (37 18%) 0.0532\n",
      "9m 32s (- 40m 40s) (38 19%) 0.0521\n",
      "9m 47s (- 40m 25s) (39 19%) 0.0515\n",
      "10m 2s (- 40m 8s) (40 20%) 0.0499\n",
      "10m 16s (- 39m 52s) (41 20%) 0.0477\n",
      "10m 31s (- 39m 36s) (42 21%) 0.0459\n",
      "10m 46s (- 39m 22s) (43 21%) 0.0455\n",
      "11m 1s (- 39m 6s) (44 22%) 0.0447\n",
      "11m 16s (- 38m 50s) (45 22%) 0.0435\n",
      "11m 31s (- 38m 34s) (46 23%) 0.0423\n",
      "11m 46s (- 38m 19s) (47 23%) 0.0409\n",
      "12m 1s (- 38m 3s) (48 24%) 0.0406\n",
      "12m 15s (- 37m 47s) (49 24%) 0.0402\n",
      "12m 30s (- 37m 32s) (50 25%) 0.0382\n",
      "12m 45s (- 37m 17s) (51 25%) 0.0386\n",
      "13m 12s (- 37m 35s) (52 26%) 0.0374\n",
      "13m 28s (- 37m 23s) (53 26%) 0.0363\n",
      "25m 41s (- 69m 29s) (54 27%) 0.0361\n",
      "43m 43s (- 115m 17s) (55 27%) 0.0353\n",
      "45m 8s (- 116m 4s) (56 28%) 0.0347\n",
      "45m 47s (- 114m 53s) (57 28%) 0.0350\n",
      "46m 22s (- 113m 33s) (58 28%) 0.0349\n",
      "47m 1s (- 112m 23s) (59 29%) 0.0348\n",
      "47m 39s (- 111m 13s) (60 30%) 0.0338\n",
      "48m 16s (- 110m 0s) (61 30%) 0.0333\n",
      "48m 55s (- 108m 54s) (62 31%) 0.0329\n",
      "49m 34s (- 107m 49s) (63 31%) 0.0323\n",
      "50m 9s (- 106m 35s) (64 32%) 0.0325\n",
      "50m 47s (- 105m 30s) (65 32%) 0.0324\n",
      "51m 27s (- 104m 28s) (66 33%) 0.0313\n",
      "52m 6s (- 103m 26s) (67 33%) 0.0324\n",
      "52m 44s (- 102m 23s) (68 34%) 0.0307\n",
      "53m 16s (- 101m 8s) (69 34%) 0.0311\n",
      "53m 46s (- 99m 51s) (70 35%) 0.0309\n",
      "54m 18s (- 98m 39s) (71 35%) 0.0312\n",
      "54m 48s (- 97m 26s) (72 36%) 0.0298\n",
      "55m 20s (- 96m 16s) (73 36%) 0.0291\n",
      "55m 50s (- 95m 4s) (74 37%) 0.0305\n",
      "56m 20s (- 93m 54s) (75 37%) 0.0287\n",
      "56m 50s (- 92m 43s) (76 38%) 0.0288\n",
      "57m 21s (- 91m 37s) (77 38%) 0.0298\n",
      "57m 49s (- 90m 27s) (78 39%) 0.0278\n",
      "58m 19s (- 89m 20s) (79 39%) 0.0287\n",
      "74m 35s (- 111m 53s) (80 40%) 0.0301\n",
      "76m 9s (- 111m 53s) (81 40%) 0.0326\n",
      "76m 25s (- 109m 58s) (82 41%) 0.0287\n",
      "76m 40s (- 108m 4s) (83 41%) 0.0273\n",
      "76m 57s (- 106m 16s) (84 42%) 0.0280\n",
      "77m 14s (- 104m 30s) (85 42%) 0.0271\n",
      "77m 30s (- 102m 44s) (86 43%) 0.0270\n",
      "77m 46s (- 101m 1s) (87 43%) 0.0270\n",
      "78m 1s (- 99m 18s) (88 44%) 0.0267\n",
      "78m 16s (- 97m 37s) (89 44%) 0.0270\n",
      "78m 31s (- 95m 58s) (90 45%) 0.0273\n",
      "78m 46s (- 94m 21s) (91 45%) 0.0263\n",
      "79m 1s (- 92m 45s) (92 46%) 0.0269\n",
      "79m 17s (- 91m 13s) (93 46%) 0.0266\n",
      "79m 34s (- 89m 43s) (94 47%) 0.0269\n",
      "79m 49s (- 88m 13s) (95 47%) 0.0264\n",
      "80m 4s (- 86m 44s) (96 48%) 0.0279\n",
      "80m 19s (- 85m 17s) (97 48%) 0.0261\n",
      "80m 34s (- 83m 51s) (98 49%) 0.0261\n",
      "80m 49s (- 82m 27s) (99 49%) 0.0274\n",
      "81m 5s (- 81m 5s) (100 50%) 0.0253\n",
      "81m 21s (- 79m 45s) (101 50%) 0.0252\n",
      "81m 36s (- 78m 24s) (102 51%) 0.0248\n",
      "81m 52s (- 77m 6s) (103 51%) 0.0256\n",
      "82m 8s (- 75m 49s) (104 52%) 0.0259\n",
      "82m 22s (- 74m 32s) (105 52%) 0.0247\n",
      "82m 37s (- 73m 16s) (106 53%) 0.0244\n",
      "82m 52s (- 72m 1s) (107 53%) 0.0245\n",
      "83m 7s (- 70m 48s) (108 54%) 0.0252\n",
      "83m 22s (- 69m 36s) (109 54%) 0.0246\n",
      "83m 37s (- 68m 25s) (110 55%) 0.0245\n",
      "83m 52s (- 67m 14s) (111 55%) 0.0249\n",
      "84m 7s (- 66m 5s) (112 56%) 0.0260\n",
      "84m 22s (- 64m 57s) (113 56%) 0.0256\n",
      "84m 37s (- 63m 50s) (114 56%) 0.0260\n",
      "84m 51s (- 62m 43s) (115 57%) 0.0243\n",
      "85m 6s (- 61m 38s) (116 57%) 0.0241\n",
      "85m 21s (- 60m 33s) (117 58%) 0.0251\n",
      "85m 36s (- 59m 29s) (118 59%) 0.0245\n",
      "85m 51s (- 58m 26s) (119 59%) 0.0241\n",
      "86m 6s (- 57m 24s) (120 60%) 0.0242\n",
      "86m 21s (- 56m 22s) (121 60%) 0.0250\n",
      "86m 36s (- 55m 22s) (122 61%) 0.0246\n",
      "86m 51s (- 54m 22s) (123 61%) 0.0232\n",
      "87m 6s (- 53m 23s) (124 62%) 0.0227\n",
      "87m 21s (- 52m 24s) (125 62%) 0.0238\n",
      "87m 36s (- 51m 26s) (126 63%) 0.0228\n",
      "87m 50s (- 50m 29s) (127 63%) 0.0237\n",
      "88m 5s (- 49m 33s) (128 64%) 0.0238\n",
      "88m 20s (- 48m 37s) (129 64%) 0.0231\n",
      "88m 35s (- 47m 42s) (130 65%) 0.0239\n",
      "88m 50s (- 46m 47s) (131 65%) 0.0229\n",
      "89m 5s (- 45m 53s) (132 66%) 0.0234\n",
      "89m 20s (- 45m 0s) (133 66%) 0.0230\n",
      "89m 35s (- 44m 7s) (134 67%) 0.0234\n",
      "89m 50s (- 43m 15s) (135 67%) 0.0231\n",
      "90m 5s (- 42m 23s) (136 68%) 0.0237\n",
      "90m 19s (- 41m 32s) (137 68%) 0.0232\n",
      "90m 34s (- 40m 41s) (138 69%) 0.0228\n",
      "90m 49s (- 39m 51s) (139 69%) 0.0227\n",
      "91m 4s (- 39m 1s) (140 70%) 0.0226\n",
      "91m 19s (- 38m 12s) (141 70%) 0.0222\n",
      "91m 34s (- 37m 24s) (142 71%) 0.0233\n",
      "91m 48s (- 36m 35s) (143 71%) 0.0245\n",
      "92m 4s (- 35m 48s) (144 72%) 0.0235\n",
      "92m 18s (- 35m 0s) (145 72%) 0.0240\n",
      "92m 33s (- 34m 14s) (146 73%) 0.0228\n",
      "92m 48s (- 33m 27s) (147 73%) 0.0238\n",
      "93m 5s (- 32m 42s) (148 74%) 0.0223\n",
      "93m 30s (- 32m 0s) (149 74%) 0.0220\n",
      "93m 44s (- 31m 14s) (150 75%) 0.0224\n",
      "101m 47s (- 33m 1s) (151 75%) 0.0225\n",
      "102m 3s (- 32m 13s) (152 76%) 0.0226\n",
      "102m 18s (- 31m 25s) (153 76%) 0.0219\n",
      "102m 33s (- 30m 38s) (154 77%) 0.0225\n",
      "102m 48s (- 29m 50s) (155 77%) 0.0221\n",
      "103m 3s (- 29m 4s) (156 78%) 0.0215\n",
      "103m 19s (- 28m 17s) (157 78%) 0.0227\n",
      "103m 34s (- 27m 31s) (158 79%) 0.0225\n",
      "103m 49s (- 26m 46s) (159 79%) 0.0228\n",
      "104m 4s (- 26m 1s) (160 80%) 0.0225\n",
      "104m 19s (- 25m 16s) (161 80%) 0.0218\n",
      "104m 34s (- 24m 31s) (162 81%) 0.0213\n",
      "104m 48s (- 23m 47s) (163 81%) 0.0212\n",
      "105m 3s (- 23m 3s) (164 82%) 0.0221\n",
      "105m 18s (- 22m 20s) (165 82%) 0.0220\n",
      "105m 33s (- 21m 37s) (166 83%) 0.0218\n",
      "105m 48s (- 20m 54s) (167 83%) 0.0226\n",
      "106m 3s (- 20m 12s) (168 84%) 0.0235\n",
      "106m 18s (- 19m 29s) (169 84%) 0.0225\n",
      "106m 33s (- 18m 48s) (170 85%) 0.0218\n",
      "106m 48s (- 18m 6s) (171 85%) 0.0219\n",
      "107m 3s (- 17m 25s) (172 86%) 0.0216\n",
      "107m 18s (- 16m 44s) (173 86%) 0.0218\n",
      "107m 33s (- 16m 4s) (174 87%) 0.0213\n",
      "107m 48s (- 15m 24s) (175 87%) 0.0212\n",
      "108m 3s (- 14m 44s) (176 88%) 0.0217\n",
      "108m 18s (- 14m 4s) (177 88%) 0.0211\n",
      "108m 32s (- 13m 24s) (178 89%) 0.0218\n",
      "108m 47s (- 12m 45s) (179 89%) 0.0221\n",
      "109m 2s (- 12m 6s) (180 90%) 0.0212\n",
      "109m 17s (- 11m 28s) (181 90%) 0.0213\n",
      "109m 32s (- 10m 50s) (182 91%) 0.0213\n",
      "109m 47s (- 10m 11s) (183 91%) 0.0213\n",
      "110m 2s (- 9m 34s) (184 92%) 0.0212\n",
      "110m 16s (- 8m 56s) (185 92%) 0.0213\n",
      "110m 31s (- 8m 19s) (186 93%) 0.0215\n",
      "110m 46s (- 7m 42s) (187 93%) 0.0215\n",
      "111m 1s (- 7m 5s) (188 94%) 0.0208\n",
      "111m 16s (- 6m 28s) (189 94%) 0.0211\n",
      "111m 31s (- 5m 52s) (190 95%) 0.0220\n",
      "111m 46s (- 5m 16s) (191 95%) 0.0211\n",
      "112m 1s (- 4m 40s) (192 96%) 0.0212\n",
      "112m 16s (- 4m 4s) (193 96%) 0.0218\n",
      "112m 31s (- 3m 28s) (194 97%) 0.0204\n",
      "112m 46s (- 2m 53s) (195 97%) 0.0215\n",
      "113m 1s (- 2m 18s) (196 98%) 0.0214\n",
      "117m 26s (- 1m 47s) (197 98%) 0.0208\n",
      "123m 27s (- 1m 14s) (198 99%) 0.0215\n",
      "123m 47s (- 0m 37s) (199 99%) 0.0212\n",
      "124m 2s (- 0m 0s) (200 100%) 0.0210\n"
     ]
    }
   ],
   "source": [
    "train(train_dataloader, encoder, decoder, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16b72150-4d36-4903-bf18-6e78ae88a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da53feff-1485-4616-8c50-9cf0d32a2fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 135842 sentence pairs\n",
      "Trimmed to 11362 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4596\n",
      "eng 2989\n",
      "['nous sommes amoureuses', 'we re in love']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "\treturn [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "\tindexes = indexesFromSentence(lang, sentence)\n",
    "\tindexes.append(EOS_token)\n",
    "\treturn torch.tensor(indexes, dtype=torch.long).view(1,-1)\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aee5a69a-6fed-4dd6-8d22-58a86faca87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> je ne vais pas autoriser ca\n",
      "= i m not going to allow that\n",
      "< i m not going to allow that anymore <EOS>\n",
      "\n",
      "> je suis implique\n",
      "= i m involved\n",
      "< i m involved <EOS>\n",
      "\n",
      "> je cherche un sac pour ma femme\n",
      "= i m looking for a bag for my wife\n",
      "< i m looking for a bag for my wife <EOS>\n",
      "\n",
      "> c est quelqu un de bien\n",
      "= he s a good person\n",
      "< he s a good person <EOS>\n",
      "\n",
      "> je suis heureux que vous l ayez aime\n",
      "= i m happy you liked it\n",
      "< i m happy you liked it <EOS>\n",
      "\n",
      "> vous etes trop tendue\n",
      "= you re too tense\n",
      "< you re too tense <EOS>\n",
      "\n",
      "> tu vas bien\n",
      "= you re all right\n",
      "< you re all right i fine <EOS>\n",
      "\n",
      "> ils ne sont pas si mauvais\n",
      "= they re not so bad\n",
      "< they re not so bad in no good <EOS>\n",
      "\n",
      "> je vais voir mary cet apres midi\n",
      "= i am seeing mary this afternoon\n",
      "< i am seeing mary this afternoon <EOS>\n",
      "\n",
      "> je suis un homme\n",
      "= i am a man\n",
      "< i am a man man <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "128ae774-e9c3-4a3b-af35-a0c411c5f19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), 'seq2seqEncoder')\n",
    "torch.save(decoder.state_dict(), 'seq2seqDecoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba0539cd-2028-4e18-9325-4bd6b25b6604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = il n est pas aussi grand que son pere\n",
      "output = he is not as tall as his father <EOS>\n",
      "input = je suis trop fatigue pour conduire\n",
      "output = i m too tired to drive <EOS>\n",
      "input = je suis desole si c est une question idiote\n",
      "output = i m sorry if this is a stupid question <EOS>\n",
      "input = je suis reellement fiere de vous\n",
      "output = i m really proud of you <EOS>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s0/65qv1d5n0qg389zx4z323j_m0000gn/T/ipykernel_64068/1690937169.py:8: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
      "/var/folders/s0/65qv1d5n0qg389zx4z323j_m0000gn/T/ipykernel_64068/1690937169.py:10: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + output_words)\n",
      "/var/folders/s0/65qv1d5n0qg389zx4z323j_m0000gn/T/ipykernel_64068/1690937169.py:16: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/var/folders/s0/65qv1d5n0qg389zx4z323j_m0000gn/T/ipykernel_64068/1690937169.py:8: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
      "/var/folders/s0/65qv1d5n0qg389zx4z323j_m0000gn/T/ipykernel_64068/1690937169.py:10: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + output_words)\n",
      "/var/folders/s0/65qv1d5n0qg389zx4z323j_m0000gn/T/ipykernel_64068/1690937169.py:16: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/var/folders/s0/65qv1d5n0qg389zx4z323j_m0000gn/T/ipykernel_64068/1690937169.py:8: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
      "/var/folders/s0/65qv1d5n0qg389zx4z323j_m0000gn/T/ipykernel_64068/1690937169.py:10: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + output_words)\n",
      "/var/folders/s0/65qv1d5n0qg389zx4z323j_m0000gn/T/ipykernel_64068/1690937169.py:16: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/var/folders/s0/65qv1d5n0qg389zx4z323j_m0000gn/T/ipykernel_64068/1690937169.py:8: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
      "/var/folders/s0/65qv1d5n0qg389zx4z323j_m0000gn/T/ipykernel_64068/1690937169.py:10: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + output_words)\n",
      "/var/folders/s0/65qv1d5n0qg389zx4z323j_m0000gn/T/ipykernel_64068/1690937169.py:16: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
    "\n",
    "\n",
    "evaluateAndShowAttention('il n est pas aussi grand que son pere')\n",
    "\n",
    "evaluateAndShowAttention('je suis trop fatigue pour conduire')\n",
    "\n",
    "evaluateAndShowAttention('je suis desole si c est une question idiote')\n",
    "\n",
    "evaluateAndShowAttention('je suis reellement fiere de vous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004dd81a-2a66-40d8-8551-2e5905d54c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
